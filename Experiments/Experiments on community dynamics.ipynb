{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e697a55",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_layer = pickle.load(open('../Multilayer Network/user_layer.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a41b0",
   "metadata": {},
   "source": [
    "# Metrics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8733d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "\n",
    "# Louvain algorithm\n",
    "partition = community.best_partition(user_layer)\n",
    "\n",
    "# Compute metrics\n",
    "modularity = community.modularity(partition, user_layer)\n",
    "community_sizes = {}\n",
    "community_embeddedness = {}\n",
    "\n",
    "for com in set(partition.values()):\n",
    "    nodes = [nodes for nodes in partition.keys() if partition[nodes] == com]\n",
    "    community_sizes[com] = len(nodes)\n",
    "    embeddedness = 0\n",
    "    for node in nodes:\n",
    "        embeddedness += sum([1 for n in user_layer.neighbors(node) if partition[n] != com])\n",
    "    community_embeddedness[com] = embeddedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.scatter(list(community_sizes.values()), list(community_embeddedness.values()))\n",
    "ax.set_xlabel(\"Community Size\")\n",
    "ax.set_ylabel(\"Community Embeddedness\")\n",
    "plt.savefig('CE_CS.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3f593",
   "metadata": {},
   "source": [
    "# Key users analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved key users\n",
    "key_users = pickle.load(open('key_users.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get biggest community: 88\n",
    "filtering = lambda x: x[1]==88\n",
    "biggest_community = dict(filter(filtering, partition.items()))\n",
    "print(len(key_users))\n",
    "print(len(biggest_community))\n",
    "print(len(set(key_users).intersection(set(biggest_community.keys()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54cee03",
   "metadata": {},
   "source": [
    "# Projection of Content layer to Social phenomenon layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd290fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLN = pickle.load(open('../Multilayer Network/MLN.pickle', 'rb'))\n",
    "content_social_layer = nx.Graph()\n",
    "for c, data in MLN.nodes(data=True):\n",
    "    if data['layer'] == 'content':\n",
    "        content_social_layer.add_node(c)\n",
    "multi_layer_edges = [(u,v,data) for u,v,data in MLN.edges(data=True) if data['layer']=='multi_c_s']\n",
    "sp_edges = [(s1,s2) for s1,s2,data in MLN.edges(data=True) if data['layer']=='socialphenomenon']\n",
    "social_to_content_map = {}\n",
    "for edge in multi_layer_edges:\n",
    "    if edge[1] not in social_to_content_map:\n",
    "        social_to_content_map[edge[1]] = []\n",
    "    social_to_content_map[edge[1]].append(edge[0])\n",
    "social_to_content_map_filtered = {}\n",
    "for s in social_to_content_map:\n",
    "    if len(social_to_content_map[s]) > 1:\n",
    "        social_to_content_map_filtered[s] = social_to_content_map[s]\n",
    "sp_edges = [(s1,s2) for s1,s2 in sp_edges if s1 in social_to_content_map_filtered.keys() or s2 in social_to_content_map_filtered.keys()]\n",
    "result = {}\n",
    "for social_node, content_nodes in social_to_content_map_filtered.items():\n",
    "    for i, c1 in enumerate(content_nodes):\n",
    "        for c2 in content_nodes[i+1:]:\n",
    "            try:\n",
    "                result[(c1,c2)].extend(social_node)\n",
    "                result[(c1,c2)] = list(set(result[(c1,c2)]))\n",
    "            except:\n",
    "                result[(c1,c2)] = [social_node]\n",
    "for res in result.keys():\n",
    "    content_social_layer.add_edge(res[0], res[1], label=result[res])\n",
    "pickle.dump(content_social_layer, open('content_social_layer.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eff02a",
   "metadata": {},
   "source": [
    "# Biggest community sub-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_social_layer = pickle.load(open('content_social_layer.pickle', 'rb'))\n",
    "MLN = pickle.load(open('../Multilayer Network/MLN.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92476b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_net = user_layer.subgraph(list(biggest_community.keys()))\n",
    "pickle.dump(b_net, open('b_net.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e061f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_content_layer = nx.Graph()\n",
    "for b, data in b_net.nodes(data=True):\n",
    "    b_content_layer.add_node(b)\n",
    "content_social_layer = pickle.load(open('content_social_layer.pickle', 'rb'))\n",
    "sc_edges = [(c1,c2,data) for c1,c2,data in content_social_layer.edges(data=True)]\n",
    "multi_layer_edges = []\n",
    "for u,v,data in MLN.edges(data=True):\n",
    "    if data['layer']=='multi_u_c':\n",
    "        if b_content_layer.has_node(u):\n",
    "            multi_layer_edges.append((u,v))\n",
    "content_to_b_map = {}\n",
    "for edge in multi_layer_edges:\n",
    "    if edge[1] not in content_to_b_map:\n",
    "        content_to_b_map[edge[1]] = []\n",
    "    content_to_b_map[edge[1]].append(edge[0])\n",
    "content_to_b_map_filtered = {}\n",
    "for b in content_to_b_map:\n",
    "    if len(content_to_b_map[b]) > 1:\n",
    "        content_to_b_map_filtered[b] = content_to_b_map[b]\n",
    "sc_edges = [(c1,c2,data) for c1,c2,data in content_social_layer.edges(data=True) if c1 in content_to_b_map_filtered.keys() or c2 in content_to_b_map_filtered.keys()]\n",
    "result = {}\n",
    "for content_node, user_nodes in content_to_b_map_filtered.items():\n",
    "    for c1,c2,data in sc_edges:\n",
    "        subtypes = []\n",
    "        if c1 == content_node or c2 == content_node:\n",
    "            subtypes.extend(data['label'])\n",
    "        subtypes = list(set(subtypes))\n",
    "        for i, u1 in enumerate(user_nodes):\n",
    "            for u2 in user_nodes[i+1:]:\n",
    "                try:\n",
    "                    result[(u1,u2)].extend(subtypes)\n",
    "                    result[(u1,u2)] = list(set(result[(u1,u2)]))\n",
    "                except:\n",
    "                    result[(u1,u2)] = subtypes\n",
    "for res in result.keys():\n",
    "    b_content_layer.add_edge(res[0], res[1], label=result[res])\n",
    "pickle.dump(b_content_layer, open('b_content_layer.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220368fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print metrics\n",
    "print(len(b_content_layer.nodes))\n",
    "print(len(b_content_layer.edges))\n",
    "print(nx.number_of_isolates(b_content_layer))\n",
    "print(nx.density(b_content_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-types occurrences plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "subtype_count = {}\n",
    "for value_list in result.values():\n",
    "    for subtype in value_list:\n",
    "        if subtype in subtype_count:\n",
    "            subtype_count[subtype] += 1\n",
    "        else:\n",
    "            subtype_count[subtype] = 1\n",
    "\n",
    "plt.bar(subtype_count.keys(), subtype_count.values())\n",
    "plt.ylim(0,130)\n",
    "plt.xlabel(\"Sub-type\")\n",
    "plt.ylabel(\"Number of Occurrences\")\n",
    "plt.savefig('subtype_occ.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
