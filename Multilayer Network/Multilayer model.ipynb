{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf46a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3cc34",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12dddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset into pandas dataframe\n",
    "df = pd.read_csv(\"../Dataset/comments_2022_step3.csv\", header=0)\n",
    "df['topics'] = df['topics'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\",'').split(', '))\n",
    "df = df.loc[df['subreddit']!='[deleted]']\n",
    "df = df.loc[df['author']!='[deleted]']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80787c48",
   "metadata": {},
   "source": [
    "### Empty multilayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create multilayer network\n",
    "MLN = nx.MultiGraph()\n",
    "pickle.dump(MLN, open('MLN.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b36318",
   "metadata": {},
   "source": [
    "### User layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca16cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in df['author'].unique():\n",
    "    MLN.add_node(user, layer='user')\n",
    "\n",
    "for row in df.groupby('subreddit')['author'].apply(list).to_frame().iterrows():\n",
    "    sub = row[0]\n",
    "    auts = list(row[1])[0]\n",
    "    if len(auts) > 1:\n",
    "        edges_u = [(a,b,sub) for idx, a in enumerate(auts) for b in auts[idx+1:]]\n",
    "        for edge in edges_u:\n",
    "            MLN.add_edge(edge[0], edge[1], layer='user', label=edge[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513a31d",
   "metadata": {},
   "source": [
    "### Content layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d954e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes\n",
    "for comment in df.iterrows():\n",
    "    MLN.add_node(comment[1]['id'], layer='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_c = []\n",
    "for i in range(0, len(df)):\n",
    "    current_id = df.iloc[i]['id']\n",
    "    current_topics = df.iloc[i]['topics']\n",
    "    for j in range(i+1, len(df)):\n",
    "        next_id = df.iloc[j]['id']\n",
    "        next_topics = df.iloc[j]['topics']\n",
    "        if len(set(current_topics).intersection(set(next_topics))) > 0:\n",
    "            edges_c.append((current_id, next_id, list(set(current_topics).intersection(set(next_topics)))))\n",
    "    if i % 1000 == 0:\n",
    "        with open(f'tmp/edges_c_{i}.pickle', 'wb') as f:\n",
    "            pickle.dump(edges_c, f)\n",
    "        del edges_c[:]\n",
    "        del edges_c\n",
    "        edges_c = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "pickles = [f for f in listdir('tmp') if isfile(join('tmp', f))]\n",
    "for file in pickles:\n",
    "    with open(f'tmp/{file}', 'rb') as f:\n",
    "        current = list(pickle.load(f))\n",
    "    for edge in current:\n",
    "        MLN.add_edge(edge[0], edge[1], layer='content', label=edge[2])\n",
    "    del current[:]\n",
    "    del current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d48d3",
   "metadata": {},
   "source": [
    "### Social phenomenon layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e753099",
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_nodes = ['A', 'M', 'L', 'S', 'I', 'E']\n",
    "for node in spl_nodes:\n",
    "    MLN.add_node(node, layer='socialphenomenon')\n",
    "spl_edges = [('A', 'M', 'similarity'), ('A', 'S', 'association'), ('A', 'I', 'causality'), ('A', 'E', 'causality'),\n",
    "            ('M', 'S', 'causality'), ('M', 'I', 'association'), ('M', 'E', 'causality'), ('L', 'S', 'association')]\n",
    "for edge in spl_edges:\n",
    "    MLN.add_edge(edge[0], edge[1], layer='socialphenomenon', label=edge[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5bd663",
   "metadata": {},
   "source": [
    "### Multi-layer edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges between U and C\n",
    "posting_edges = list(df[['author', 'id']].itertuples(index=False, name=None))\n",
    "df_interactions = df[['author', 'id', 'parent_id']].copy()\n",
    "df_interactions['parent_id'] = df_interactions['parent_id'].apply(lambda x: x.split('_')[1])\n",
    "df_interactions = df_interactions.loc[df_interactions['parent_id'].isin(list(df_interactions['id']))]\n",
    "interactions_edges = list(df_interactions[['author', 'parent_id']].itertuples(index=False, name=None))\n",
    "u_c_edges = []\n",
    "u_c_edges.extend(posting_edges)\n",
    "u_c_edges.extend(interactions_edges)\n",
    "for edge in u_c_edges:\n",
    "    MLN.add_edge(edge[0], edge[1], layer='multi_u_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges between C and S\n",
    "c_s_edges = []\n",
    "for row in df[['id', 'sub-types']].itertuples():\n",
    "    _id = row[1]\n",
    "    _sts = row[2]\n",
    "    for st in _sts:\n",
    "        c_s_edges.append((_id, st))\n",
    "for edge in c_s_edges:\n",
    "    MLN.add_edge(edge[0], edge[1], layer='multi_c_s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a702cd3",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1edd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nodes and edges with no \"layer\"\n",
    "nodes_to_remove = [node for node in MLN.nodes() if 'layer' not in MLN.nodes[node]]\n",
    "edges_to_remove = [(u, v) for u, v, data in MLN.edges(data=True) if 'layer' not in data]\n",
    "MLN.remove_nodes_from(nodes_to_remove)\n",
    "MLN.remove_edges_from(edges_to_remove)\n",
    "pickle.dump(MLN, open('MLN.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9631d74",
   "metadata": {},
   "source": [
    "# Descriptive analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_graph(G, layer):\n",
    "    sub_graph = nx.Graph()\n",
    "    for node, data in G.nodes(data=True):\n",
    "        if 'layer' in data and data['layer'] == layer:\n",
    "            sub_graph.add_node(node, **data)\n",
    "    for node1, node2, data in G.edges(data=True):\n",
    "        if 'layer' in data and data['layer'] == layer:\n",
    "            sub_graph.add_edge(node1, node2, **data)\n",
    "    return sub_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af119ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_layer = get_sub_graph(MLN, 'user')\n",
    "print(f'Nodes {len(user_layer.nodes)}')\n",
    "print(f'Edges {len(user_layer.edges)}')\n",
    "conn_comps = list(nx.connected_components(user_layer))\n",
    "print(f'Num conn comp {len(conn_comps)}')\n",
    "print(f'Max conn comp {len(max(conn_comps))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = get_sub_graph(MLN, 'content')\n",
    "print(f'Nodes {len(content_layer.nodes)}')\n",
    "print(f'Edges {len(content_layer.edges)}')\n",
    "conn_comps = list(nx.connected_components(content_layer))\n",
    "print(f'Num conn comp {len(conn_comps)}')\n",
    "print(f'Max conn comp {len(max(conn_comps))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcfba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(user_layer, open('user_layer.pickle', 'wb'))\n",
    "pickle.dump(content_layer, open('content_layer.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb54c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'User density {nx.density(user_layer)}')\n",
    "print(f'Content density {nx.density(content_layer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926488d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(u_c_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a35bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_edges = [u[0] for u in u_c_edges]\n",
    "len(set(user_layer.nodes).difference(set(nodes_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e218e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_edges = [u[0] for u in c_s_edges]\n",
    "len(set(content_layer.nodes).difference(set(nodes_edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e8792",
   "metadata": {},
   "source": [
    "# Draw graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "user_layer = pickle.load(open('user_layer.pickle', 'rb'))\n",
    "content_layer = pickle.load(open('content_layer.pickle', 'rb'))\n",
    "\n",
    "connected_components = nx.connected_components(user_layer)\n",
    "biggest_cc = max(connected_components, key=len)\n",
    "nodes = list(biggest_cc)\n",
    "\n",
    "for u, v, data in MLN.edges(data=True):\n",
    "    if data['layer'] == 'multi_u_c' and u in nodes:\n",
    "        nodes.append(v)\n",
    "for u, data in MLN.nodes(data=True):\n",
    "    if data['layer'] == 'socialphenomenon':\n",
    "        nodes.append(u)\n",
    "        \n",
    "del user_layer\n",
    "del content_layer\n",
    "\n",
    "def draw_multilayer_graph(G):\n",
    "    pos = nx.spring_layout(G)\n",
    "    node_labels = {}\n",
    "    for node, data in G.nodes(data=True):\n",
    "        node_labels[node] = node\n",
    "        if data['layer'] == 'user':\n",
    "            nx.draw_networkx_nodes(G, pos, [node], node_size=50, node_color='red')\n",
    "        elif data['layer'] == 'content':\n",
    "            nx.draw_networkx_nodes(G, pos, [node], node_size=50, node_color='green')\n",
    "        elif data['layer'] == 'socialphenomenon':\n",
    "            nx.draw_networkx_nodes(G, pos, [node], node_size=50, node_color='blue')\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if data['layer'] == 'multi_u_c':\n",
    "            nx.draw_networkx_edges(G, pos, [(u, v)], edge_color='red', width=1.0)\n",
    "        elif data['layer'] == 'multi_c_s':\n",
    "            nx.draw_networkx_edges(G, pos, [(u, v)], edge_color='green', width=1.0)\n",
    "    nx.draw_networkx_labels(G, pos, node_labels)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Take a part of the graph MLN\n",
    "sub_graph = nx.Graph(MLN.subgraph(nodes))\n",
    "draw_multilayer_graph(sub_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
